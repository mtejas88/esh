## =========================================================================
##
## QA CAMPUSING 2017
## Sierra Costanza
##
## Procedure:
## Within each campus id (with 2 or more schools) generated by Adrianna in 
## "final_campuses_school_level_for_engineering.csv", calculate the pairwise
## distance between all schools. For the ones that are > 0.1 miles, check that 
## they are <= 0.1 miles with at least 1 school in the campus. For the cases that 
## donâ€™t meet this, check whether they were forced by DQT (and with the same 
## lat-long as 2016) or same address
##
## =========================================================================


## Clearing memory
rm(list=ls())

## load packages (if not already in the environment)
packages.to.install <- c("DBI", "rJava", "RJDBC", "dotenv","geosphere", "caTools", "dplyr","dtplyr", "data.table")
for (i in 1:length(packages.to.install)){
  if (!packages.to.install[i] %in% rownames(installed.packages())){
    install.packages(packages.to.install[i])
  }
}
library(geosphere)
library(caTools)
library(dplyr)
library(dtplyr) 
library(data.table) ## for the as.data.table function
library(DBI)
library(rJava)
library(RJDBC)
library(dotenv)

# set up workding directory -- it is currently set up to the folder which contains all scripts
#this is my github path. DONT FORGET TO COMMENT OUT
github_path <- '~/Documents/ESH/ficher/'


options(java.parameters = "-Xmx4g" )

## source environment variables
source(paste(github_path, "General_Resources/common_functions/source_env.R", sep=""))
source_env("~/.env")

## source correct_ids function
source(paste(github_path, "General_Resources/common_functions/correct_nces_ids.R", sep=""))

##**************************************************************************************************************************************************
## QUERY THE DB
## load PostgreSQL Driver
pgsql <- JDBC("org.postgresql.Driver", paste(github_path, "General_Resources/postgres_driver/postgresql-9.4.1212.jre7.jar", sep=""), "`")

## connect to the database
con <- dbConnect(pgsql, url=url, user=user, password=password)
## schools to nces code mapping table
schools_nces <- dbGetQuery(con, "select*from public.entity_nces_codes")
## disconnect from database
dbDisconnect(con)

##******************************************************************************************************************/
## READING IN AND SUBSETTING DATA
nces <- read.csv("data/nces_schools_subset.csv", as.is=T, header=T, stringsAsFactors=F)
# correct ids
nces$ncessch <- correct_ids(nces$ncessch,district = 0)
## round 2017 lat/long coordinates to 4 decimal places to match last year's calcalation
## (since some campuses didn't stick due to the slight difference in calculation)
nces$latcode <- round(nces$latcode, digits=4)
nces$longcode <- round(nces$longcode, digits=4)

## get final campuses
campus_schools=read.csv("data/final_campuses_school_level_for_engineering.csv", as.is=T, header=T, stringsAsFactors=F)
#attach nces code
campus_schools <- merge(campus_schools, schools_nces[,c("entity_id", "nces_code")],
             by.x="school_esh_id", by.y="entity_id", all.x=T)

#make into a list so it's easier to loop through campuses
campus_schools_list <- aggregate(nces_code ~ campus_id_2017, campus_schools, I)
#filter for campuses with > 1 school
campus_schools_list_2p <- campus_schools_list[sapply(campus_schools_list$nces_code,length) > 1,]
##******************************************************************************************************************/
## CALCULATE PAIRWISE DISTANCE BETWEEN ALL SCHOOLS IN A CAMPUS
dta <- NULL
system.time({
  for (c in campus_schools_list_2p$campus_id_2017){
       sub=as.data.frame(unlist(campus_schools_list_2p %>% filter(
       campus_id_2017==c) %>% select(nces_code),recursive = FALSE))
       pair=as.data.table(t(combn(sub$nces_code, 2)))
       pair$campus_id_2017=c
       dta <- rbind(dta, pair)
  }
})
names(dta) <- c("school1", "school2","campus_id_2017")

## merge in district and lat/long information for each school
dta <- merge(dta, nces[,c("ncessch", "leaid", "latcode", "longcode", "combined.addr")],
             by.x="school1", by.y="ncessch", all.x=T, allow.cartesian=T)
dta <- merge(dta, nces[,c("ncessch", "leaid", "latcode", "longcode", "combined.addr")],
             by.x="school2", by.y="ncessch", all.x=T, allow.cartesian=T)
names(dta) <- c("school2", "school1", "campus_id_2017", "district1", "lat1", "long1", "combined.addr1",
                "district2", "lat2", "long2", "combined.addr2")

## calculate distances within all combinations of schools
## takes ~3 sec to run
system.time({
  dta[,distance_hav := distHaversine(matrix(c(dta$long1, dta$lat1), ncol = 2),
                                     matrix(c(dta$long2, dta$lat2), ncol = 2))]
  ## convert to miles
  dta$distance_hav <- dta$distance_hav * 0.000621371
})

## take out the schools that don't have lat/long info or missing distance
dta <- dta[dta$lat1 != 0 & dta$long1 != 0,]
dta.na=dta[is.na(dta$distance_hav),]
dta <- dta[!is.na(dta$distance_hav),]
##******************************************************************************************************************/
## CHECK ALL PAIRS WITH > 0.1 MI DISTANCE - if they are within 0.1 mi from any other school in their campus

dta.g.1 <- dta[dta$distance_hav > 0.1,]
#grab all unique schools in this list and their campuses
sch1=dta.g.1[,c(1,3:7)]
sch2=dta.g.1[,c(2,3,8:11)]
names(sch1)=c("school","campus_id_2017","district","lat","long","combined.addr")
names(sch2)=c("school","campus_id_2017","district","lat","long","combined.addr")
allschools.g.1=union(sch1,sch2)

## Check that they are <= 0.1 miles away from at least 1 school in the remaining schools in the campus
  #this is equivalent to seeing that if you merge on the remaining dataset with schools pairs <= 0.1 mi away
  #in the same campus, you should be able to match all the schools in allschools.g.1 to either school 1 or school 2
dta.le.1=setdiff(dta,dta.g.1)
max(dta.le.1$distance_hav) #0.09999498

sch1=merge(allschools.g.1,dta.le.1[,c("school1","campus_id_2017","distance_hav")],by.x=c("school","campus_id_2017"), by.y=c("school1","campus_id_2017"))
sch2=merge(allschools.g.1,dta.le.1[,c("school2","campus_id_2017","distance_hav")],by.x=c("school","campus_id_2017"), by.y=c("school2","campus_id_2017"))
allschools.g.check=as.data.frame(union(sch1$school,sch2$school))
colnames(allschools.g.check)="school"
allschools.g.check$school=as.character(allschools.g.check$school)

##****************************************************************************************************************/
## CHECK ALL PAIRS WITH > 0.1 MI DISTANCE AND ARE NOT WITH 0.1 MI OF ANY OTHER SCHOOL IN THEIR CAMPUS - 
## if they are in the same district and have the same address

## function to extend dataset to all combinations
all.combos <- function(dta){
  dta.ext <- dta[,c("school2", "school1")]
  names(dta.ext) <- c("school1", "school2")
  dta <- rbind(dta, dta.ext)
  return(dta)
}

#Remove the schools that were within 0.1 of at least 1 school
dta.g.1.remaining=dta.g.1[(!(dta.g.1$school1 %in% allschools.g.check$school)), ]
dta.g.1.remaining=dta.g.1.remaining[(!(dta.g.1.remaining$school2 %in% allschools.g.check$school)), ]
summary(dta.g.1.remaining$distance_hav)

### Collect all unique addresses shared by more than 1 school
## force the combined address to only work when the district id is the same, so add it to the combined address field
nces$combined.addr.rev <- paste(nces$combined.addr, nces$leaid, sep=" ")
duplicated.addr <- nces$combined.addr[which(duplicated(nces$combined.addr))]
duplicated.addr <- unique(duplicated.addr)
duplicated.addr <- duplicated.addr[!is.na(duplicated.addr)]
## subset to those addresses
#sub.duplicated <- nces[which(nces$combined.addr.rev %in% duplicated.addr),]
sub.duplicated <- nces[which(nces$combined.addr %in% duplicated.addr),]

### For each unique duplicated address, find all combinations of schools
## takes ~1 min to run the loop
system.time({
  dta.same.addr.pairs <- NULL
  for (i in 1:length(duplicated.addr)){
    dta.sub <- nces[which(nces$combined.addr == duplicated.addr[i]),]
    dta.same.addr.pairs <- rbind(dta.same.addr.pairs, as.data.table(t(combn(dta.sub$ncessch, 2))))
  }
})
## name the columns
names(dta.same.addr.pairs) <- c("school1", "school2")

dta.same.addr.pairs <- all.combos(dta.same.addr.pairs)
## order the dataset by school1
dta.same.addr.pairs <- dta.same.addr.pairs[order(dta.same.addr.pairs$school1),]
## create a unique combination identifier
dta.same.addr.pairs$combo <- paste(dta.same.addr.pairs$school1, dta.same.addr.pairs$school2, sep=".")

## subset the remaining dataset to just be the school pairs
dta.g.1.remaining <- dta.g.1.remaining[,c("school1", "school2")]
## extend distance dataset to all combinations of the schools with the same address
## also so every school can be found in the first column
dta.g.1.remaining <- all.combos(dta.g.1.remaining)
## order the dataset by school1
dta.g.1.remaining <- dta.g.1.remaining[order(dta.g.1.remaining$school1),]
## create a unique combination identifier
dta.g.1.remaining$combo <- paste(dta.g.1.remaining$school1, dta.g.1.remaining$school2, sep=".")

## get remaining pairs without the same address
dta.g.1.remaining=dta.g.1.remaining[which(!dta.g.1.remaining$combo %in% dta.same.addr.pairs$combo),]

##****************************************************************************************************************/
## CHECK ALL PAIRS WITH > 0.1 MI DISTANCE AND ARE NOT WITH 0.1 MI OF ANY OTHER SCHOOL IN THEIR CAMPUS  
## AND DON'T HAVE THE SAME ADDRESS AS ANY OTHER SCHOOL IN THE CAMPUS
## if they were a DQT forced pair and didn't change lat/long

## 2016 campus overrides by DQT (only when the location of the school didn't change from 2016 to 2017)
dta.dqt.2016 <- read.csv("data/2016_DQT_override_forced_school_pairs.csv", as.is=T, header=T, stringsAsFactors=F)

## correct ids
dta.dqt.2016$school1 <- correct_ids(dta.dqt.2016$school1, district=0)
dta.dqt.2016$school2 <- correct_ids(dta.dqt.2016$school2, district=0)

## extend data frame for the dqt overrides
dta.dqt.2016 <- all.combos(dta.dqt.2016)
## create combination indicator for dqt forced pairs
dta.dqt.2016$combo <- paste(dta.dqt.2016$school1, dta.dqt.2016$school2, sep=".")

## get remaining pairs without the same address
dta.g.1.remaining=dta.g.1.remaining[which(!dta.g.1.remaining$combo %in% dta.dqt.2016$combo),]

campuses.remaining=merge(dta.g.1.remaining[,c("school1")],campus_schools[,c("nces_code","campus_id_2017")],by.x="school1",by.y="nces_code",all.x=TRUE)
campuses.remaining=merge(campuses.remaining, nces[,c("ncessch", "leaid", "latcode", "longcode", "combined.addr")],
                         by.x="school1",by.y="ncessch",all.x=TRUE)
campuses.remaining.list <- aggregate(school1 ~ campus_id_2017, campuses.remaining, paste, collapse = ",")
exceptions=NULL
for (c in campuses.remaining.list$campus_id_2017){
  sub=as.data.frame(strsplit(as.character(
    campuses.remaining.list %>% filter(
      campus_id_2017==c) %>% select(school1)),","))
  names(sub)="school"
  sub=merge(sub, campuses.remaining, by.x="school",by.y="school1")
  sub$dist=distHaversine(c(sub$longcode[1],sub$latcode[1]), c(sub$longcode[2],sub$latcode[2]))* 0.000621371
  exceptions=rbind(exceptions,sub)
}

write.csv(exceptions, "exceptions_export.csv", row.names=F)