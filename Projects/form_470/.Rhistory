dta.470$quantity == 0),]
dta.470.wan.unknown <- rbind(dta.470.wan.unknown, dta.470.wan.unknown2)
dta.470.wan.unknown <- dta.470.wan.unknown[which(!dta.470.wan.unknown$x470.number %in% dta.470.wan$x470.number),]
dta.470.wan.unknown$meeting_goals_wan <- 'UNKNOWN'
length(unique(dta.470.wan.unknown$x470.number))
##**************************************************************************************************************************************************
## merge together the indicators
dta.470.ia.sub <- dta.470.ia[,c('esh_id', 'x470.number', 'meeting_goals_ia_2014', 'meeting_goals_ia_2018')]
dta.470.ia.sub <- unique(dta.470.ia.sub)
dta.470.ia.sub <- rbind(dta.470.ia.sub, dta.470.ia.unknown[,c('esh_id', 'x470.number', 'meeting_goals_ia_2014', 'meeting_goals_ia_2018')])
dta.470.sub <- merge(dta.470.ia.sub, dta.470.wan[,c('esh_id', 'x470.number', 'meeting_goals_wan')], by=c('esh_id', 'x470.number'), all=T)
dta.470.wan.unknown$meeting_goals_ia_2014 <- NA
dta.470.wan.unknown$meeting_goals_ia_2018 <- NA
dta.470.wan.unknown <- dta.470.wan.unknown[,c('esh_id', 'x470.number', 'meeting_goals_ia_2014', 'meeting_goals_ia_2018', 'meeting_goals_wan')]
dta.470.sub <- rbind(dta.470.sub, dta.470.wan.unknown)
dta.470.sub <- unique(dta.470.sub)
##**************************************************************************************************************************************************
## write out the interim datasets
write.csv(dta.470.sub, "data/processed/470_status.csv", row.names=F)
write.csv(dta.470.ia, "data/interim/470_ia_status.csv", row.names=F)
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/processed/470_status.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
View(dta.470.ia)
names(dta.470.ia)
table(dta.470.ia$minimum.capacity)
table(dta.470.ia$maximum.capacity)
sub <- dta.470.ia[which(dta.470.ia$meeting_goals_ia_2014 == TRUE &
dta.470.ia$minimum.capacity == "10 Mbps" &
dta.470.ia$maximum.capacity == 25000),]
View(sub)
write.csv(sub, "data/interim/scoping_1_mtg_2014_ia_min_10mbps_max_25gbps.csv", row.names=F)
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
names(dta.470)
table(dta.470$service.type)
table(dta.470$function1)
names(dta.470)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
setwd("~/Google Drive/St")
setwd("~/Google Drive/ESH Main Share/Strategic Analysis Team/2017/Org-Wide Projects/service_provider_ranking/")
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
jeremy.qa <- read.csv("QA/data/jeremy_output_03-14-2017.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/service_provider_aggregated_clean_districts.csv", as.is=T, header=T, stringsAsFactors=F)
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
jeremy.qa <- read.csv("QA/data/jeremy_output_03-14-2017.csv", as.is=T, header=T, stringsAsFactors=F)
dta.sp <- read.csv("data/interim/service_provider_aggregated_clean_districts.csv", as.is=T, header=T, stringsAsFactors=F)
##**************************************************************************************************************************************************
sp.agg <- aggregate(jeremy.qa$num_districts_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
sp.agg.students <- aggregate(jeremy.qa$num_students_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
names(sp.agg.students) <- c('service_provider', 'num_students_served_jeremy')
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
jeremy.qa <- read.csv("QA/data/jeremy_output_03-14-2017.csv", as.is=T, header=T, stringsAsFactors=F)
dta.sp <- read.csv("data/interim/service_provider_aggregated_clean_districts.csv", as.is=T, header=T, stringsAsFactors=F)
##**************************************************************************************************************************************************
sp.agg <- aggregate(jeremy.qa$num_districts_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
sp.agg.students <- aggregate(jeremy.qa$num_students_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
names(sp.agg.students) <- c('service_provider', 'num_students_served_jeremy')
dta.compare <- merge(sp.agg, dta.sp[,c('service_provider', 'num_districts_served')], by='service_provider', all=T)
View(dta.sp)
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
jeremy.qa <- read.csv("QA/data/jeremy_output_03-14-2017.csv", as.is=T, header=T, stringsAsFactors=F)
dta.sp <- read.csv("data/interim/service_provider_aggregated_clean_districts.csv", as.is=T, header=T, stringsAsFactors=F)
sp.agg <- aggregate(jeremy.qa$num_districts_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
names(sp.agg.students) <- c('service_provider', 'num_districts_served_jeremy')
names(sp.agg) <- c('service_provider', 'num_districts_served_jeremy')
dta.compare <- merge(sp.agg, dta.sp[,c('service_provider', 'num_districts_served')], by='service_provider', all=T)
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
jeremy.qa <- read.csv("QA/data/jeremy_output_03-14-2017.csv", as.is=T, header=T, stringsAsFactors=F)
dta.sp <- read.csv("data/interim/service_provider_aggregated_clean_districts.csv", as.is=T, header=T, stringsAsFactors=F)
##**************************************************************************************************************************************************
sp.agg <- aggregate(jeremy.qa$num_districts_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
names(sp.agg) <- c('service_provider', 'num_districts_served_jeremy')
dta.compare <- merge(sp.agg, dta.sp[,c('service_provider', 'num_districts_served')], by='service_provider', all=T)
sp.agg.students <- aggregate(jeremy.qa$num_students_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
names(sp.agg.students) <- c('service_provider', 'num_students_served_jeremy')
dta.sp$num_students_served <- dta.sp$num_students_not_meeting_goal + dta.sp$num_students_meeting_goal
dta.compare.students <- merge(sp.agg.students, dta.sp[,c('service_provider', 'num_students_served')],
by='service_provider', all=T)
dta.compare$diff <- dta.compare$num_districts_served_jeremy - dta.compare$num_districts_served
dta.compare.students$diff <- dta.compare.students$num_students_served_jeremy - dta.compare.students$num_students_served
View(dta.compare.students)
table(dta.compare$diff)
sub <- dta.compare[dta.compare$diff != 0,]
sub <- dta.compare[which(dta.compare$diff != 0),]
View(sub)
table(dta.compare.students$diff)
sub <- dta.compare.students[which(dta.compare.students$diff != 0),]
## ===========================================================================================================================
##
## QA: This script compares Jeremy's SP-State output with the SP ranking used for 2016 National Analysis
##
## ===========================================================================================================================
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
jeremy.qa <- read.csv("QA/data/jeremy_output_03-14-2017.csv", as.is=T, header=T, stringsAsFactors=F)
dta.sp <- read.csv("data/interim/service_provider_aggregated_clean_districts.csv", as.is=T, header=T, stringsAsFactors=F)
##**************************************************************************************************************************************************
sp.agg <- aggregate(jeremy.qa$num_districts_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
names(sp.agg) <- c('service_provider', 'num_districts_served_jeremy')
dta.compare <- merge(sp.agg, dta.sp[,c('service_provider', 'num_districts_served')], by='service_provider', all=T)
dta.compare$diff <- dta.compare$num_districts_served_jeremy - dta.compare$num_districts_served
## 2 SPs differ
table(dta.compare$diff)
sub <- dta.compare[which(dta.compare$diff != 0),]
## because Services Received reporting name was not updated with the Charter, ENA fixes (since Jeremy is merging on that field)
sp.agg.students <- aggregate(jeremy.qa$num_students_served, by=list(jeremy.qa$reporting_name), FUN=sum, na.rm=T)
names(sp.agg.students) <- c('service_provider', 'num_students_served_jeremy')
dta.sp$num_students_served <- dta.sp$num_students_not_meeting_goal + dta.sp$num_students_meeting_goal
dta.compare.students <- merge(sp.agg.students, dta.sp[,c('service_provider', 'num_students_served')],
by='service_provider', all=T)
dta.compare.students$diff <- dta.compare.students$num_students_served_jeremy - dta.compare.students$num_students_served
## 28 SPs differ
table(dta.compare.students$diff)
sub <- dta.compare.students[which(dta.compare.students$diff != 0),]
## because for National Analysis, we took out districts where the SP was allowing them to meet goals but the district was not actually meeting
## this is because they provide upstream but the BW the district is receiving is actually limited by their ISP
##**************************************************************************************************************************************************
## write out data
write.csv(dta.compare, "QA/data/compare_districts.csv", row.names=F)
write.csv(dta.compare.students, "QA/data/compare_students.csv", row.names=F)
## ==============================================================================================================================
##
## REFRESH STATE METRICS
## STEP #2 in refreshing the state metric tool.
##
## Refreshes the State Metrics with the new data, stores the data, and deploys the tool.
## To be used for the interactive state metrics tool devloped by Sujin, edited by Adrianna
##
## C2 info comes from two sources:
## 1) Current: https://modeanalytics.com/educationsuperhighway889/reports/0111c885c5aa/runs/310bd53edaa7
## 2) SoTS: \Google Drive\ESH Main Share\Strategic Analysis Team\Archived\2015\State of the States\State Snapshot\Final Workbooks\state_snap_static_1112 FINAL.xlsx, Summary tab, column AR
##
## ==============================================================================================================================
## Clearing memory
rm(list=ls())
setwd("~/Google Drive/ESH Main Share/Strategic Analysis Team/2016/Org-wide Projects/Progress Tracking/Snapshots/sm_dashboard_master/metrics/code/")
## read in libraries
library(rJava)
library(RJDBC)
library(RPostgreSQL)
library(DBI)
## read in functions
func.dir <- "functions/"
func.list <- list.files(func.dir)
for (file in func.list[grepl('.R', func.list)]){
source(paste(func.dir, file, sep=''))
}
## retrieve date (in order to accurately timestamp files)
date <- Sys.time()
weekday <- weekdays(date)
date <- gsub("PST", "", date)
date <- gsub(" ", "_", date)
date <- gsub(":", ".", date)
##*********************************************************************************************************
## OPTIONS
## set 1 to also deploy state metric tool
deploy <- 1
## option to revert the tool to the previous data
#revert <- 0
##*********************************************************************************************************
## QUERY THE DB -- SQL
## load PostgreSQL Driver
drv <- JDBC("org.postgresql.Driver", "~/Downloads/postgresql-9.4.1209.jar", "`")
## connect to the database
con <- dbConnect(drv, url="jdbc:postgresql://ec2-34-192-172-58.compute-1.amazonaws.com:5432/dai3g95tesvtj9?ssl=true&sslfactory=org.postgresql.ssl.NonValidatingFactory",
user="ud1bnbevrqe2q", password="p412da0cf141f10788be82e8a3d0dc8e24698205ec718e9db75cd86aabd6b67c4")
## query function
querydb <- function(query_name) {
query <- readChar(query_name, file.info(query_name)$size)
data <- dbGetQuery(con, query)
return(data)
}
dd.2015 <- querydb("SQL scripts/2015_deluxe_districts_crusher_materialized.SQL")
fiber.2015 <- querydb("SQL scripts/2015_current_fiber_metrics.SQL")
ds.2015 <- querydb("SQL scripts/2015_deluxe_schools_crusher_materialized.SQL")
dd.2016 <- querydb("SQL scripts/2016_deluxe_districts_crusher_materialized.SQL")
ds.2016 <- querydb("SQL scripts/2016_deluxe_schools_crusher_materialized.SQL")
## Combine 2015 fiber metrics with 2015 DD
## take out ia_monthly_cost columns, except for "ia_monthly_cost"
monthly.cost.cols <- names(fiber.2015)[grepl("ia_monthly_cost", names(fiber.2015))]
monthly.cost.cols <- monthly.cost.cols[monthly.cost.cols != "ia_monthly_cost"]
fiber.2015 <- fiber.2015[,!names(fiber.2015) %in% monthly.cost.cols]
## also take out columns that already exist in dd.2015
fiber.2015 <- fiber.2015[,names(fiber.2015)[!names(fiber.2015) %in% names(dd.2015)]]
## sub in the new 2015 fiber files for the old ones in dd.2015
dd.2015 <- merge(dd.2015, fiber.2015, by.x='esh_id', by.y='district_esh_id', all.x=T)
dd.2015$ia_monthly_cost <- NULL
## correct the columns
dd.2015 <- correct.dataset(dd.2015, sots.flag = 0, services.flag = 0)
ds.2015 <- correct.dataset(ds.2015, sots.flag = 0, services.flag = 0)
dd.2016 <- correct.dataset(dd.2016, sots.flag = 0, services.flag = 0)
ds.2016 <- correct.dataset(ds.2016, sots.flag = 0, services.flag = 0)
## disconnect from database
dbDisconnect(con)
## read in State of the States 2015 published data
sots.2015 <- read.csv("../data/raw/aggregated_metrics/2015_state_of_the_states.csv", as.is=T, header=T, stringsAsFactors=FALSE)
sots.2015.ranks <- read.csv("../data/raw/aggregated_metrics/sots15_ranks.csv", as.is=T, header=T, stringsAsFactors=FALSE)
sots.districts.2015 <- read.csv("../data/raw/deluxe_districts/2015_state_of_the_states_districts.csv", as.is=T, header=T, stringsAsFactors=FALSE)
#sots.sr.2015 <- read.csv("../data/raw/services_received/2015_state_of_the_states_services_received.csv", as.is=T, header=T, stringsAsFactors=FALSE)
## read in C2 info
## current 2015 & 2016
c2.current <- read.csv("../data/raw/c2/all_things_c2_fy_2015_and_2016-query_2016-11-03.csv", as.is=T, header=T, stringsAsFactors=FALSE)
c2.sots <- read.csv("../data/raw/c2/C2_state-of-the-states.csv", as.is=T, header=T, stringsAsFactors=FALSE)
## correct the columns
sots.districts.2015 <- correct.dataset(sots.districts.2015, sots.flag = 1, services.flag = 0)
##*********************************************************************************************************
## CALCULATE METRICS BY SOURCING FUNCTIONS
## make sure to subset to include_in_universe_of_districts first for 2016
dd.2016 <- dd.2016[dd.2016$include_in_universe_of_districts == TRUE,]
dd.2016 <- dd.2016[!dd.2016$district_type %in% c("BIE", "Charter"),]
dd.2016 <- dd.2016[!duplicated(dd.2016$esh_id),]
## take out DC in both years
#dd.2016 <- dd.2016[dd.2016$postal_cd != 'DC',]
#dd.2015 <- dd.2015[dd.2015$postal_cd != 'DC',]
## sub in "Small" to "Town"
dd.2016$locale[grepl("Town", dd.2016$locale)] <- gsub("Town", "Small Town", dd.2016$locale[grepl("Town", dd.2016$locale)])
## format service provider information
dd.2015 <- combine.sp(dd.2015)
dd.2016 <- combine.sp(dd.2016)
## fix dd.2015 monthly_ia_cost_per_mbps
dd.2015$ia_monthly_cost_per_mbps <- suppressWarnings(as.numeric(dd.2015$monthly_ia_cost_per_mbps, na.rm=T))
## merge in extra information for schools-level analysis
ds.2015 <- merge(ds.2015, dd.2015[,c('esh_id', 'locale', 'district_size', 'district_type', "address", "city", "zip",
"frl_percent", "num_internet_upstream_lines", "bundled_and_dedicated_isp_sp", 'lines_w_dirty',
"most_recent_ia_contract_end_date", "fiber_internet_upstream_lines")],
by.x='district_esh_id', by.y='esh_id', all.x=T)
ds.2016 <- merge(ds.2016, dd.2016[,c('esh_id', 'locale', 'district_size', 'district_type', "address", "city", "zip",
'num_internet_upstream_lines', 'bundled_and_dedicated_isp_sp',
'exclude_from_wan_analysis', 'exclude_from_ia_cost_analysis', 'lines_w_dirty', 'needs_wifi',
"non_fiber_internet_upstream_lines_w_dirty", "fiber_internet_upstream_lines_w_dirty",
"most_recent_ia_contract_end_date", "non_fiber_lines", "fiber_wan_lines", "fiber_internet_upstream_lines")],
by.x='district_esh_id', by.y='esh_id', all.x=T)
states.with.schools <- c('DE', 'HI', 'RI')
names(ds.2016)[names(ds.2016) %in% c('district_fiber_target_status', 'district_bw_target_status')] <- c('fiber_target_status', 'bw_target_status')
names(ds.2015)[names(ds.2015) == 'district_esh_id'] <- 'esh_id'
names(ds.2015)[names(ds.2015) == 'district_name'] <- 'name'
names(ds.2016)[names(ds.2016) == 'district_esh_id'] <- 'esh_id'
names(ds.2016)[names(ds.2016) == 'district_name'] <- 'name'
dd.2015 <- dd.2015[,names(dd.2015) %in% names(ds.2015)]
dd.2015$campus_id <- NA
dd.2015$school_esh_ids <- NA
ds.2015 <- ds.2015[,match(names(dd.2015), names(ds.2015))]
dd.2016 <- dd.2016[,names(dd.2016) %in% names(ds.2016)]
dd.2016$campus_id <- NA
dd.2016$school_esh_ids <- NA
ds.2016 <- ds.2016[,match(names(dd.2016), names(ds.2016))]
## assign datasets as masters since they'll get rewritten
dd.2016.master <- dd.2016
ds.2016.master <- ds.2016
dd.2015.master <- dd.2015
ds.2015.master <- ds.2015
sots.districts.2015.master <- sots.districts.2015
## generate dta for each subset: all data, rural, and urban districts
for (i in 1:3){
print(i)
if (i == 1){
dd.2016 <- dd.2016.master
ds.2016 <- ds.2016.master
dd.2015 <- dd.2015.master
ds.2015 <- ds.2015.master
sots.districts.2015 <- sots.districts.2015.master
dd.2016 <- dd.2016[dd.2016$locale == 'Rural',]
ds.2016 <- ds.2016[ds.2016$locale == 'Rural',]
dd.2015 <- dd.2015[dd.2015$locale == 'Rural',]
ds.2015 <- ds.2015[ds.2015$locale == 'Rural',]
sots.districts.2015 <- sots.districts.2015[sots.districts.2015$locale == 'Rural',]
district.label <- "rural"
}
if (i == 2){
dd.2016 <- dd.2016.master
ds.2016 <- ds.2016.master
dd.2015 <- dd.2015.master
ds.2015 <- ds.2015.master
sots.districts.2015 <- sots.districts.2015.master
dd.2016 <- dd.2016[dd.2016$locale == 'Urban',]
ds.2016 <- ds.2016[ds.2016$locale == 'Urban',]
dd.2015 <- dd.2015[dd.2015$locale == 'Urban',]
ds.2015 <- ds.2015[ds.2015$locale == 'Urban',]
sots.districts.2015 <- sots.districts.2015[sots.districts.2015$locale == 'Urban',]
district.label <- "urban"
}
if (i == 3){
district.label <- ""
dd.2016 <- dd.2016.master
ds.2016 <- ds.2016.master
dd.2015 <- dd.2015.master
ds.2015 <- ds.2015.master
sots.districts.2015 <- sots.districts.2015.master
}
## prep dataset
dta <- data.frame(postal_cd=c(sots.2015$postal_cd, "DC", "ALL"), state_name=c(sots.2015$state.name, "DC", "National"))
## call on functions to calculate stats
population_and_samples(sots.2015, sots.districts.2015, dd.2015, ds.2015, dd.2016, ds.2016, dta, states.with.schools)
upgrades(dd.2015, ds.2015, dd.2016, ds.2016, dta, states.with.schools)
connectivity(sots.districts.2015, dd.2015, ds.2015, dd.2016, ds.2016, dta, dd.clean.compare, dd.2016.with.2015.leftover, states.with.schools)
fiber(sots.2015, dd.2015, ds.2015, dd.2016, ds.2016, dta, states.with.schools)
affordability(sots.districts.2015, dd.2015, ds.2015, dd.2016, ds.2016, dta, states.with.schools)
wifi(sots.2015, dd.2016, ds.2016, dta, c2.sots, c2.current, states.with.schools)
## reorder dta alphabetically by state
## first, take out national number
national.dta <- dta[dta$postal_cd == 'ALL',]
dta <- dta[dta$postal_cd != 'ALL',]
## order the dataset
dta <- dta[order(dta$postal_cd),]
## add back in the national number
dta <- rbind(dta, national.dta)
## make sure DC is out
dta <- dta[dta$postal_cd != 'DC',]
## adjust the school level metrics
dta <- adjust.school.level.metrics(dta, states.with.schools, dd.clean.compare, i)
assign(paste("dta", district.label, sep=''), dta)
}
## also merge in the published numbers for SotS
published.sots.2015(dta, sots.2015)
## create the exportable snapshot dataset
snapshots(dta, dtarural, dtaurban)
##*********************************************************************************************************
## WRITE OUT FILES
if (weekday == 'Monday'){
## deluxe districts
write.csv(dd.2015, paste("../data/raw/deluxe_districts/2015-districts-deluxe-crusher-materialized-", date, ".csv", sep=''), row.names=F)
write.csv(ds.2015, paste("../data/raw/deluxe_districts/2015-schools-deluxe-crusher-materialized-", date, ".csv", sep=''), row.names=F)
write.csv(dd.2016, paste("../data/raw/deluxe_districts/2016-districts-deluxe-endpoint-", date, ".csv", sep=''), row.names=F)
write.csv(ds.2016, paste("../data/raw/deluxe_districts/2016-schools-deluxe-crusher-materialized-", date, ".csv", sep=''), row.names=F)
}
## new weekly refresh stats
#write.csv(dta, paste("../data/processed/master_metrics/master_metrics_", date, ".csv", sep=''), row.names=F)
## districts upgraded
#write.csv(dd.clean.compare, paste("../data/processed/upgrades/districts_upgraded_as_of_", date, ".csv", sep=''), row.names=F)
#write.csv(dd.clean.compare.states.with.schools, paste("../data/processed/upgrades/schools_upgraded_as_of_", date, ".csv", sep=''), row.names=F)
## targets
#write.csv(connectivity.targets, paste("../data/processed/targets/connectivity_targets_", date, ".csv", sep=''), row.names=F)
#write.csv(fiber.targets, paste("../data/processed/targets/fiber_targets_", date, ".csv", sep=''), row.names=F)
## click through data
#write.csv(current15.click.through.districts, paste("../data/processed/click_through/current15_districts_click_through_", date, ".csv", sep=''), row.names=F)
#write.csv(current16.click.through.districts, paste("../data/processed/click_through/current16_districts_click_through_", date, ".csv", sep=''), row.names=F)
#write.csv(connectivity.click.through, paste("../data/processed/click_through/connectivity_click_through_", date, ".csv", sep=''), row.names=F)
#write.csv(fiber.click.through, paste("../data/processed/click_through/fiber_click_through_", date, ".csv", sep=''), row.names=F)
#write.csv(affordability.click.through, paste("../data/processed/click_through/affordability_click_through_", date, ".csv", sep=''), row.names=F)
## snapshots
#write.csv(snapshot, paste("../data/processed/snapshots/snapshots_", date, ".csv", sep=''), row.names=F)
## LIVE
## also copy over the files to the state metrics tool data directory
tool.data.dir <- "../../tool/data/"
## deluxe districts
write.csv(sots.districts.2015, paste(tool.data.dir, "2015-state-of-the-states-districts.csv", sep=''), row.names=F)
write.csv(dd.2015, paste(tool.data.dir, "2015-districts-deluxe.csv", sep=''), row.names=F)
write.csv(dd.2016, paste(tool.data.dir, "2016-districts-deluxe.csv", sep=''), row.names=F)
## click-throughs
write.csv(current15.click.through.districts, paste(tool.data.dir, "current15_districts_click_through.csv", sep=''), row.names=F)
write.csv(current16.click.through.districts, paste(tool.data.dir, "current16_districts_click_through.csv", sep=''), row.names=F)
write.csv(connectivity.click.through, paste(tool.data.dir, "connectivity_click_through.csv", sep=''), row.names=F)
write.csv(fiber.click.through, paste(tool.data.dir, "fiber_click_through.csv", sep=''), row.names=F)
write.csv(affordability.click.through, paste(tool.data.dir, "affordability_click_through.csv", sep=''), row.names=F)
## targets
write.csv(connectivity.targets, paste(tool.data.dir, "connectivity_targets.csv", sep=''), row.names=F)
write.csv(fiber.targets, paste(tool.data.dir, "fiber_targets.csv", sep=''), row.names=F)
## upgrades
write.csv(dd.clean.compare, paste(tool.data.dir, "districts_upgraded.csv", sep=''), row.names=F)
## master metrics
write.csv(dta, paste(tool.data.dir, "master_metrics.csv", sep=''), row.names=F)
## snapshots
write.csv(snapshot, paste(tool.data.dir, "snapshots.csv", sep=''), row.names=F)
## write out the date from which the data has been updated
write.csv(date, paste(tool.data.dir, "date.csv", sep=''), row.names=F)
##*********************************************************************************************************
## DEPLOY TOOL
if (deploy == 1){
rsconnect::deployDoc("../../tool/state_metric_dashboard.Rmd")
}
setwd("~/Documents/ESH-Code/ficher/Projects/form_470/")
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
sub <- dta.470[which(dta.470$service.type == "Internet Access and/or Telecommunications" &
dta.470$function1 == "Lit Fiber Service"),]
table(dta.470.ia)
table(dta.470.ia$meeting_goals_ia_2014)
View(dta.470.ia)
names(dta.470.ia)
table(is.na(dta.470.ia$meeting_goals_ia_2014))
sub.ia.eval <- dta.470.ia[dta.470.ia$meeting_goals_ia_2014 %in% c(TRUE, FALSE),]
ids.duplicated <- dta.470.ia$esh_id[which(duplicated$esh_id)]
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
##**************************************************************************************************************************************************
## apply criteria
sub <- dta.470[which(dta.470$service.type == "Internet Access and/or Telecommunications" &
dta.470$function1 == "Lit Fiber Service"),]
## find districts that only have 1 Form 470 that was evaluated as Meeting 2014 IA Goals
sub.ia.eval <- dta.470.ia[dta.470.ia$meeting_goals_ia_2014 %in% c(TRUE, FALSE),]
ids.duplicated <- dta.470.ia$esh_id[which(duplicated$esh_id)]
ids.duplicated <- dta.470.ia$esh_id[which(duplicated(dta.470.ia$esh_id))]
ids.not.duplicated <- dta.470.ia$esh_id[which(!dta.470.ia$esh_id %in% ids.duplicated)]
sub <- sub[which(sub$esh_id %in% ids.duplicated),]
View(sub)
length(unique(sub$esh_id))
names(dta.470.ia)
names(sub)
sub <- merge(sub, dta.470.ia[c('x470.number', 'meeting_goals_ia_2014')], by='x470.number', all.x=T)
View(sub)
sub <- sub[which(!is.na(sub$meeting_goals_ia_2014)),]
View(sub)
table(sub$meeting_goals_ia_2014)
write.csv(sub, "data/interim/scoping_2_districts_ia_fiber_only_1_470_eligible_for_ia_meeting_goals.csv", row.names=F)
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
##**************************************************************************************************************************************************
## apply criteria
sub <- dta.470[which(dta.470$service.type == "Internet Access and/or Telecommunications" &
dta.470$function1 == "Lit Fiber Service"),]
View(dta.470.ia)
sub <- dta.470.ia[which(dta.470.ia$service.type == "Internet Access and/or Telecommunications" &
dta.470.ia$function1 == "Lit Fiber Service"),]
names(dta.470.ia)
table(dta.470.ia$service.type)
table(dta.470.ia$function1)
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
setwd("~/Documents/ESH-Code/ficher/Projects/form_470/")
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
sub <- dta.470.ia[which(dta.470.ia$service.type == "Internet Access and/or Telecommunications" &
dta.470.ia$function1 == "Lit Fiber Service"),]
## find districts that only have 1 Form 470 that was evaluated as Meeting 2014 IA Goals
sub.ia.eval <- dta.470.ia[dta.470.ia$meeting_goals_ia_2014 %in% c(TRUE, FALSE),]
ids.duplicated <- dta.470.ia$esh_id[which(duplicated(dta.470.ia$esh_id))]
ids.not.duplicated <- dta.470.ia$esh_id[which(!dta.470.ia$esh_id %in% ids.duplicated)]
sub <- sub[which(sub$esh_id %in% ids.duplicated),]
sub <- dta.470[which(dta.470$service.type == "Internet Access and/or Telecommunications" &
dta.470$function1 == "Lit Fiber Service"),]
sub.ia.eval <- dta.470.ia[dta.470.ia$meeting_goals_ia_2014 %in% c(TRUE, FALSE),]
ids.duplicated <- dta.470.ia$esh_id[which(duplicated(dta.470.ia$esh_id))]
ids.not.duplicated <- dta.470.ia$esh_id[which(!dta.470.ia$esh_id %in% ids.duplicated)]
sub <- sub[which(sub$esh_id %in% ids.duplicated),]
View(sub)
ids.with.470 <- unique(sub.ia.eval$esh_id)
sub <- sub[which(!sub$esh_id %in% ids.with.470),]
## ===========================================================================================================================
##
## SCOPING 2: Districts have a Form 470 where Service Type = 'Internet Access and/or Telecommunications'
##            AND Function = ‘Lit Fiber Service'
##                AND there are no other Form 470s on the district that are “Meeting 2014 IA Goals’ = ‘True’ or ‘False’
##  (i.e. they have no other Form 470s at all, or their Form 470s are listed as ’N/A’ or ‘Unknown’ for “Meeting 2014 IA Goals”)
##
## ===========================================================================================================================
## Clearing memory
rm(list=ls())
##**************************************************************************************************************************************************
## READ IN DATA
dta.470 <- read.csv("data/interim/470_all.csv", as.is=T, header=T, stringsAsFactors=F)
dta.470.ia <- read.csv("data/interim/470_ia_status.csv", as.is=T, header=T, stringsAsFactors=F)
##**************************************************************************************************************************************************
## apply criteria
sub <- dta.470[which(dta.470$service.type == "Internet Access and/or Telecommunications" &
dta.470$function1 == "Lit Fiber Service"),]
## find districts that only have 1 Form 470 that was evaluated as Meeting 2014 IA Goals
sub.ia.eval <- dta.470.ia[dta.470.ia$meeting_goals_ia_2014 %in% c(TRUE, FALSE),]
ids.with.470 <- unique(sub.ia.eval$esh_id)
sub <- sub[which(!sub$esh_id %in% ids.with.470),]
View(sub)
length(unique(sub$esh_id))
duplicated.esh <- sub$esh_id[which(duplicated(sub$esh_id))]
sub.sub <- sub[which(sub$esh_id %in% duplicated.esh),]
View(sub.sub)
sub.sub <- sub.sub[order(sub.sub$esh_id),]
View(sub.sub)
write.csv(sub, "data/interim/scoping_2_districts_ia_fiber_only_1_470_eligible_for_ia_meeting_goals.csv", row.names=F)
