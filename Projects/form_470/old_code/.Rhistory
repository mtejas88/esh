library(leaflet)
library(ggvis)
library(shinydashboard)
library(DT) #for datatables
library(shinyjs) #for reset button
library(mapview)
library(leaflet)
library(ggvis)
library(shinydashboard)
library(DT) #for datatables
library(shinyjs) #for reset button
library(mapview)
shiny::runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
## Create reactive functions for both services received and districts table ##
library(shiny)
library(tidyr)
library(dplyr)
library(ggplot2)
library(scales)
library(grid)
library(maps)
library(ggmap)
library(reshape)
library(leaflet)
library(ggvis)
library(DT)
library(shinydashboard)
library(extrafontdb)
library(extrafont)
library(leaflet)
library(ggvis)
library(shinydashboard)
library(DT) #for datatables
library(shinyjs) #for reset button
library(mapview)
sketch = htmltools::withTags(table(
class = 'display',
thead(
tr(
th(rowspan = 2, 'Species'),
th(colspan = 2, 'Sepal'),
th(colspan = 2, 'Petal')
),
tr(
lapply(rep(c('Length', 'Width'), 2), th)
)
)
))
print(sketch)
lapply(rep(c('Length', 'Width'), 2), th)
tr(
lapply(rep(c('Length', 'Width'), 2), th)
)
sketch = htmltools::withTags(table(
class = 'display',
thead(
tr(
th(rowspan = 2, 'Postal Code'),
th(rowspan = 2, 'Locale'),
th(colspan = 2, 'Clean'),
th(colspan = 2, 'All')
),
tr(
lapply(rep(c('Length', 'Width'), 2), th)
)
)
))
print(sketch)
shiny::runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
options(shiny.reactlog=TRUE)
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
install.packages("googleVis")
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
which R
install.packages("rJava")
library(rJava)
dta <- read.csv("~/Downloads/final_campus_groupings_2016-08-31_school_level.csv", as.is=T, header=T)
nces.raw <- read.csv("~/Downloads/sc131a.csv", as.is=T, header=T)
dta.campus <- read.csv("~/Downloads/final_campus_groupings_2016-08-31.csv", as.is=T, header=T)
nces.raw$combined.addr <- paste(nces.raw$LSTREE, nces.raw$LCITY, nces.raw$LSTATE, nces.raw$LZIP, sep=' ')
View(dta)
View(nces.raw)
real.schools <- read.csv("~/Downloads/fy2016_schools_demog_2016-08-30.csv", as.is=T, header=T)
View(real.schools)
names(real.schools)
real.schools$combined.addr <- paste(real.schools$address, real.schools$city, real.schools$postal_cd, real.schools$zip, sep=' ')
View(real.schools)
dta <- merge(dta, real.schools[,c("school_esh_id", "combined.addr")], by="school_esh_id")
View(dta)
View(dta.campus)
dta.agg <- aggregate(dta$combined.addr, by=list(dta$campus_id), FUN=length(unique(x)))
dta.agg <- aggregate(dta$combined.addr, by=list(dta$campus_id), FUN=function(x){y <- length(unique(x)); return(y)})
## aggregate number of unique addresses by campus id
dta.agg <- aggregate(dta$combined.addr, by=list(dta$campus_id),
FUN=function(x){length(unique(x))})
dta <- read.csv("~/Downloads/final_campus_groupings_2016-08-31_school_level.csv", as.is=T, header=T)
dta.campus <- read.csv("~/Downloads/final_campus_groupings_2016-08-31.csv", as.is=T, header=T)
#nces.raw <- read.csv("~/Downloads/sc131a.csv", as.is=T, header=T)
real.schools <- read.csv("~/Downloads/fy2016_schools_demog_2016-08-30.csv", as.is=T, header=T)
real.schools$combined.addr <- paste(real.schools$address, real.schools$city, real.schools$postal_cd, real.schools$zip, sep=' ')
## merge in address info to campus
dta <- merge(dta, real.schools[,c("school_esh_id", "combined.addr")], by="school_esh_id")
## aggregate number of unique addresses by campus id
#dta.agg <- aggregate(dta$combined.addr, by=list(dta$campus_id),
#                     FUN=function(x){length(unique(x))})
dta.store <- as.data.frame(campus_id == unique(dta$campus_id))
dta.store <- as.data.frame(campus_id = unique(dta$campus_id))
View(dta)
length(unique(dta$campus_id))
dta.store <- as.data.frame(campus_id = unique(dta$campus_id))
dta.store <- data.frame(campus_id = unique(dta$campus_id))
View(dta)
View(dta.campus)
dta <- merge(dta, dta.campus[,c("campus.id", "num.schools")], by.x="campus_id", by.y="campus.id", all.x=T)
View(dta)
table(dta$num.schools)
View(dta.campus)
dta.campus$campus.id <- paste("campus_", dta.campus$campus.id, sep='')
dta$num.schools <- NULL
dta <- merge(dta, dta.campus[,c("campus.id", "num.schools")], by.x="campus_id", by.y="campus.id", all.x=T)
View(dta)
dta <- dta[dta$num.schools > 1,]
View(dta)
dta.store <- data.frame(campus_id = unique(dta$campus_id))
View(dta.store)
for (i in 1:nrow(dta.store$campus_id)){
dta.sub <- dta[dta$campus_id == dta.store$campus_id[i],]
dta.store$unq.add[i] <- length(unique(dta.sub$combined.addr))
}
nrow(dta.store$campus_id)
View(dta.store)
nrow(dta.store)
for (i in 1:nrow(dta.store)){
dta.sub <- dta[dta$campus_id == dta.store$campus_id[i],]
dta.store$unq.add[i] <- length(unique(dta.sub$combined.addr))
}
View(dta.store)
table(dta.store$unq.add)
nrow(dta.store[dta.store$unq.add > 1,])
nrow(dta.store[dta.store$unq.add > 1,]) / nrow(dta.store)
sample.camp.ids <- sample(dta.store$campus_id[dta.store$unq.add > 1], 10, replace=F)
sub <- dta[dta$campus_id == sample.camp.ids[2],]
View(sub)
sub <- dta[dta$campus_id == sample.camp.ids[3],]
View(sub)
sub <- dta[dta$campus_id == sample.camp.ids[4],]
View(sub)
shiny::runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
shiny::runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
runApp('Desktop/ficher/Shiny')
shiny::runApp('Desktop/ficher/Shiny')
a <- c(0,1,2,3,4,5)
combn(a,2)
x <- 54
y <- 55
x=y
if (x=y)
ifelse(x=y)
x
y
which(x=y)
if (x==y)
^c
x==y
x <- 40
y <- 40
x <= y
as.factor(x)
factor(x)
is.factor(x)
dta <- read.csv("~/Downloads/470_status.csv", as.is=T, header=T, stringsAsFactors = F)
View(dta)
sub <- dta[dta$esh_id == 881807,]
View(sub)
## Clearing memory
rm(list=ls())
sys.calls()[[1]] [[2]]
wd <- setwd(".")
setwd(wd)
## =====================================================================================================
##
## OKR #2: FORM 470
##
## =====================================================================================================
## Clearing memory
rm(list=ls())
## running locally or on the server:
local <- 1
#install.packages("DBI", repos="http://cran.rstudio.com/")
#install.packages("rJava", repos="http://cran.rstudio.com/")
#install.packages("RJDBC", repos="http://cran.rstudio.com/")
## set the current directory as the working directory
if (local == 1){
setwd("~/Documents/ESH-Code/ficher/Projects/form_470/code/")
} else{
wd <- setwd(".")
setwd(wd)
}
## load packages
## force rJava to load on Mac 10 El Capitan
#dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
options(java.parameters = "-Xmx4g" )
library(rJava)
library(RJDBC)
## retrieve date (in order to accurately timestamp files)
date <- Sys.time()
date <- gsub("PST", "", date)
date <- gsub(" ", "_", date)
date <- gsub(":", ".", date)
## source function
if (local == 1){
path.to.database.info <- "../../../R_database_access/"
} else{
path.to.database.info <- "../../R_database_access/"
}
source(paste(path.to.database.info, "correct_dataset.R", sep=""))
source(paste(path.to.database.info,"db_credentials.R", sep=""))
## QUERY THE DB -- SQL
## load PostgreSQL Driver
pgsql <- JDBC("org.postgresql.Driver", paste(path.to.database.info, "postgresql-9.4.1212.jre7.jar", sep=""), "`")
## connect to the database
con <- dbConnect(pgsql, url=url, user=user, password=password)
## query function
querydb <- function(query_name){
query <- readChar(query_name, file.info(query_name)$size)
data <- dbGetQuery(con, query)
return(data)
}
dta.470 <- querydb(paste(path.to.database.info, "SQL Scripts/Form470s.SQL", sep=""))
bens <- querydb(paste(path.to.database.info, "SQL Scripts/Entity_Bens.SQL", sep=""))
dd.2016 <- querydb(paste(path.to.database.info, "SQL Scripts/2016_deluxe_districts_crusher_materialized_all.SQL", sep=""))
dd.2016 <- correct.dataset(dd.2016, sots.flag = 0, services.flag = 0)
## disconnect from database
dbDisconnect(con)
## format the column names (take out capitalization and spaces)
names(dta.470) <- tolower(names(dta.470))
names(dta.470) <- gsub(" ", ".", names(dta.470))
## rename column "function"
names(dta.470)[names(dta.470) == 'function'] <- 'function1'
## rename column "470.number"
names(dta.470)[names(dta.470) == '470.number'] <- 'X470.number'
## convert capacity to numeric
dta.470$maximum.capacity.reported <- dta.470$maximum.capacity
dta.470$maximum.capacity <- suppressWarnings(ifelse(grepl('Mbps', dta.470$maximum.capacity), as.numeric(gsub('Mbps', '', dta.470$maximum.capacity)),
as.numeric(gsub('Gbps', '', dta.470$maximum.capacity))*1000))
## merge in BENs to DD
dd.2016 <- merge(dd.2016, bens, by.x='esh_id', by.y='entity_id', all.x=T)
## merge in number of students and number of campuses
dta.470 <- merge(dta.470, dd.2016[,c('ben', 'esh_id', 'num_students', 'num_campuses')], by='ben', all.x=T)
## the possible missing BENS (NA number of students),
## could be things we don't care about (ie Libraries)
## OR could be one-school districts that used their school BEN instead of their district BEN
## for now, take them out
dta.470.na.students <- dta.470[which(is.na(dta.470$num_students)),]
dta.470 <- dta.470[which(!is.na(dta.470$num_students)),]
## take out the BENs that file multiple 470s and subset to the most recent one filed (as long as the same service)
##**************************************************************************************************************************************************
## IA Meeting Goals
## Service Type = 'Internet Access and/or Telecommunications'
dta.470.ia <- dta.470[which(dta.470$service.category == "Internet Access and/or Telecommunications"),]
table(dta.470.ia$function1)
## Clearing memory
rm(list=ls())
## running locally or on the server:
local <- 1
#install.packages("DBI", repos="http://cran.rstudio.com/")
#install.packages("rJava", repos="http://cran.rstudio.com/")
#install.packages("RJDBC", repos="http://cran.rstudio.com/")
## set the current directory as the working directory
if (local == 1){
setwd("~/Documents/ESH-Code/ficher/Projects/form_470/code/")
} else{
wd <- setwd(".")
setwd(wd)
}
## load packages
## force rJava to load on Mac 10 El Capitan
#dyn.load('/Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/jre/lib/server/libjvm.dylib')
options(java.parameters = "-Xmx4g" )
library(rJava)
library(RJDBC)
## retrieve date (in order to accurately timestamp files)
date <- Sys.time()
date <- gsub("PST", "", date)
date <- gsub(" ", "_", date)
date <- gsub(":", ".", date)
## source function
if (local == 1){
path.to.database.info <- "../../../R_database_access/"
} else{
path.to.database.info <- "../../R_database_access/"
}
source(paste(path.to.database.info, "correct_dataset.R", sep=""))
source(paste(path.to.database.info,"db_credentials.R", sep=""))
##*********************************************************************************************************
## QUERY THE DB -- SQL
## load PostgreSQL Driver
pgsql <- JDBC("org.postgresql.Driver", paste(path.to.database.info, "postgresql-9.4.1212.jre7.jar", sep=""), "`")
## connect to the database
con <- dbConnect(pgsql, url=url, user=user, password=password)
## query function
querydb <- function(query_name){
query <- readChar(query_name, file.info(query_name)$size)
data <- dbGetQuery(con, query)
return(data)
}
dta.470 <- querydb(paste(path.to.database.info, "SQL Scripts/Form470s.SQL", sep=""))
bens <- querydb(paste(path.to.database.info, "SQL Scripts/Entity_Bens.SQL", sep=""))
dd.2016 <- querydb(paste(path.to.database.info, "SQL Scripts/2016_deluxe_districts_crusher_materialized_all.SQL", sep=""))
dd.2016 <- correct.dataset(dd.2016, sots.flag = 0, services.flag = 0)
## disconnect from database
dbDisconnect(con)
## format the column names (take out capitalization and spaces)
names(dta.470) <- tolower(names(dta.470))
names(dta.470) <- gsub(" ", ".", names(dta.470))
## rename column "function"
names(dta.470)[names(dta.470) == 'function'] <- 'function1'
## rename column "470.number"
names(dta.470)[names(dta.470) == '470.number'] <- 'X470.number'
## convert capacity to numeric
dta.470$maximum.capacity.reported <- dta.470$maximum.capacity
dta.470$maximum.capacity <- suppressWarnings(ifelse(grepl('Mbps', dta.470$maximum.capacity), as.numeric(gsub('Mbps', '', dta.470$maximum.capacity)),
as.numeric(gsub('Gbps', '', dta.470$maximum.capacity))*1000))
## merge in BENs to DD
dd.2016 <- merge(dd.2016, bens, by.x='esh_id', by.y='entity_id', all.x=T)
## merge in number of students and number of campuses
dta.470 <- merge(dta.470, dd.2016[,c('ben', 'esh_id', 'num_students', 'num_campuses')], by='ben', all.x=T)
## the possible missing BENS (NA number of students),
## could be things we don't care about (ie Libraries)
## OR could be one-school districts that used their school BEN instead of their district BEN
## for now, take them out
dta.470.na.students <- dta.470[which(is.na(dta.470$num_students)),]
dta.470 <- dta.470[which(!is.na(dta.470$num_students)),]
dta.470.ia <- dta.470.ia[which(dta.470.ia$quantity == 1 | is.na(dta.470.ia$quantity)),]
## IA Meeting Goals
## Service Type = 'Internet Access and/or Telecommunications'
dta.470.ia <- dta.470[which(dta.470$service.category == "Internet Access and/or Telecommunications"),]
## AND Function in ('Internet Access: ISP Service Only', 'Internet Access and Transport Bundled')
dta.470.ia <- dta.470.ia[which(dta.470.ia$function1 == 'Internet Access and Transport Bundled' |
dta.470.ia$function1 == 'Internet Access: ISP Service Only' & is.na(dta.470.ia$quantity)),]
dta.470.ia <- dta.470.ia[which(dta.470.ia$quantity == 1 | is.na(dta.470.ia$quantity)),]
dta.470.ia2 <- dta.470[which(dta.470$service.category == "Internet Access and/or Telecommunications" &
dta.470$function1 == 'Other'),]
dta.470.ia <- rbind(dta.470.ia, dta.470.ia2)
## AND maximum capacities are meeting the 2014 connectivity goal
## find the max of the maximum capacities reported for each ID
max.capacity <- suppressWarnings(aggregate(dta.470.ia$maximum.capacity, by=list(dta.470.ia$X470.number), FUN=max, na.rm=T))
names(max.capacity) <- c('X470.number', 'maximum.capacity')
## merge in the number of students
max.capacity <- merge(max.capacity, dta.470.ia[,c('X470.number', 'num_students')], by='X470.number', all.x=T)
max.capacity$bw_per_student <- (max.capacity$maximum.capacity*1000) / max.capacity$num_students
max.capacity$meeting_goals_ia_2014 <- ifelse(max.capacity$bw_per_student >= 100, TRUE, FALSE)
max.capacity$meeting_goals_ia_2018 <- ifelse(max.capacity$bw_per_student >= 1000, TRUE, FALSE)
## how many are meeting goals?
table(max.capacity$meeting_goals_ia_2014)
ia.meeting.goals <- max.capacity$X470.number[max.capacity$meeting_goals_ia_2014 == TRUE]
## merge in the meeting goal status
dta.470.ia <- merge(dta.470.ia, max.capacity[,c('X470.number', 'meeting_goals_ia_2014', 'meeting_goals_ia_2018')],
by='X470.number', all.x=T)
## overwrite the goal meeting status if the function is Other
dta.470.ia$meeting_goals_ia_2014 <- ifelse(dta.470.ia$function1 == 'Other', NA, dta.470.ia$meeting_goals_ia_2014)
dta.470.ia$meeting_goals_ia_2018 <- ifelse(dta.470.ia$function1 == 'Other', NA, dta.470.ia$meeting_goals_ia_2018)
View(dta.470.ia)
sub <- dta.470.ia[dta.470.ia$function1 == 'Other',]
View(sub)
table(sub$function1)
table(sub$meeting_goals_ia_2014)
