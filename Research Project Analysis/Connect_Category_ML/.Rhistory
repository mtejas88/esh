### Predicting Districts Meeting Goals ###
library(class)
library(caret)
library(dplyr)
raw <- read.csv('raw_update.csv') # predictors
install.packages(c("boot", "Matrix", "mgcv", "nlme", "nnet"))
library(class)
library(caret)
install.packages("caret")
install.packages("dplyr")
raw <- read.csv('raw_update.csv') # predictors
raw <- read.csv('raw_update.csv') # predictors
raw <- read.csv('raw_update.csv') # predictors
raw <- read.csv('raw_update.csv') # predictors
raw <- read.csv('raw_update.csv') # predictors
raw <- read.csv('./raw_update.csv') # predictors
raw <- read.csv('raw_update.csv') # predictors
raw <- read.csv('raw_update.csv')
source('~/Desktop/ESH/ficher/Research Project Analysis/Meeting Goals Prediction/meet_goals_prediction.R', echo=TRUE)
raw <- read.csv('raw_update.csv') # predictors
ver <- read.csv('verified_update.csv') # outcome
ver <- ver[!is.na(ver$ia_bandwidth_per_student),]
sort(raw$esh_id) == sort(ver$esh_id)
nrow(ver)
raw <- raw %>% arrange(esh_id)
raw <- read.csv('raw_update.csv') # predictors
x <- 2 * 4
x <- 2 * 4
x
library(class)
library(caret)
library(dplyr)
raw_update <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Meeting Goals Prediction/raw_update.csv")
View(raw_update)
raw <- read.csv('raw_update.csv') # predictors
raw
raw <- raw %>% arrange(esh_id)
sort(raw$esh_id) == sort(ver$esh_id)
library(class)
library(caret)
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML")
original_line_items <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/original_line_items.csv")
View(original_line_items)
verified_line_items_reeeal <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/verified_line_items_reeeal.csv")
View(verified_line_items_reeeal)
verified_line_items_real <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/verified_line_items_real.csv")
View(verified_line_items_real)
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/original_line_items.csv")
View(original_line_items)
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/original_line_items.csv")
View(raw_lis)
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/verified_line_items_real.csv")
View(verified_lis)
View(raw_lis)
View(verified_lis)
joined <- merge(raw_lis, verified_lis, by.x=c("frn_complete"), by.y=c("frn_complete"))
View(joined)
View(joined)
head(joined)
unique(is.na(joined$postal_cd.x))
unique(is.na(joined$bandwidth_in_mbps.x))
unique(is.na(joined$bandwidth_in_mbps.x))
nrow(joined)
joined <- joined[!is.na(joined$bandwidth_in_mbps.x)]
joined <- joined[!is.na(joined$bandwidth_in_mbps.x),]
mrow(joined)
nrow(joined)
unique(is.na(joined$num_students.x))
nrow(joined)
unique(is.na(joined$num_students.x))
joined <- joined[!is.na(joined$num_students.x),]
nrow(joined)
unique(is.na(joined$connect_category.x))
unique(is.na(joined$cost_per_line.x))
unique(is.na(joined$district_esh_id))
unique(is.na(joined$ben))
unique(is.na(joined$free_and_reduced))
unique(is.na(joined$providers_typical_category))
unique(is.na(joined$highest_connect_type))
unique(is.na(joined$num_services))
unique(is.na(joined$num_of_services))
nrow(joined)
joined <- joined[!is.na(joined$num_of_services),]
nrow(joined)
unique(is.na[joined$bandwidth_in_mbps.y])
unique(is.na(joined$bandwidth_in_mbps.y)
unique(is.na(joined$bandwidth_in_mbps.y))
unique(is.na(joined$num_students.x))
unique(is.na(joined$num_students.y))
unique(is.na(joined$cost_per_line.y))
nrow(joined)
nrow(joined) # 2512 Observations before splitting
data.size <- nrow(joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
train_data <- joined[training_id_integers,]
nrow(train_data)
View(train_data)
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/original_line_items.csv")
View(raw_lis)
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/verified_line_items_real.csv")
joined <- merge(raw_lis, verified_lis, by.x=c("frn_complete"), by.y=c("frn_complete"))
View(joined)
View(train_data)
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y + num_students.y + num_of_services + highest_connect_type + postal_cd.x + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/original_line_items.csv")
# View(raw_lis)
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/verified_line_items_real.csv")
# View(verified_lis)
# Inner join both datasets
joined <- merge(raw_lis, verified_lis, by.x=c("frn_complete"), by.y=c("frn_complete"))
# View(joined)
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
unique(is.na(joined$bandwidth_in_mbps.x))
nrow(joined)
joined <- joined[!is.na(joined$bandwidth_in_mbps.x),]
nrow(joined)
unique(is.na(joined$num_students.x))
joined <- joined[!is.na(joined$num_students.x),]
nrow(joined)
unique(is.na(joined$num_of_services))
joined <- joined[!is.na(joined$num_of_services),]
nrow(joined) # 2512 Observations before splitting
### Translate into current ML work ###
data.size <- nrow(joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce unexpected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- joined[training_id_integers,]
nrow(train_data) # 2010 to train with
# View(train_data)
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y + num_students.y + num_of_services + highest_connect_type + postal_cd.x + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
test_data <- joined[-training_id_integers,]
nrow(test_data)
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest)
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
View(results)
connect.forest$importance
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y + num_students.y + num_of_services + highest_connect_type + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
predict.forest <- predict(connect.forest, test_data)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
connect.forest$importance
varImpPlot(connect.forest)
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + num_students.y + num_of_services + highest_connect_type + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
predict.forest <- predict(connect.forest, test_data)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y + num_students.y + num_of_services + highest_connect_type + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
predict.forest <- predict(connect.forest, test_data)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
varImpPlot(connect.forest)
varImpPlot(connect.forest)
connect.forest$importance
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + postal_cd.x + cost_per_line.y + num_students.y + num_of_services + highest_connect_type + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y + num_students.y + num_of_services + highest_connect_type + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y + num_students.y + num_of_services + highest_connect_type + providers_typical_category + free_and_reduced, data=train_data, importance=T, ntree=501)
predict.forest <- predict(connect.forest, test_data)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest, raw_cat = test_data$connect_category.x)
View(results)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest, raw_cat = test_data$connect_category.x, test_data$line_item_id.x)
View(results)
View(test_data)
results <- data.frame(test_data$connect_category.y, prediction = predict.forest, raw_cat = test_data$connect_category.x, test_data$frn_complete)
View(results)
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.x, test_data$frn_complete)
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y
+ num_students.y + num_of_services
+ highest_connect_type + providers_typical_category
+ free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
# Importing data and setting the current working directory.
# install.packages('caret', dependencies = TRUE)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/original_line_items.csv")
# View(raw_lis)
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/verified_line_items_real.csv")
# View(verified_lis)
# Inner join both datasets
joined <- merge(raw_lis, verified_lis, by.x=c("frn_complete"), by.y=c("frn_complete"))
# View(joined)
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
unique(is.na(joined$bandwidth_in_mbps.x))
nrow(joined)
joined <- joined[!is.na(joined$bandwidth_in_mbps.x),]
nrow(joined)
unique(is.na(joined$num_students.x))
joined <- joined[!is.na(joined$num_students.x),]
nrow(joined)
unique(is.na(joined$num_of_services))
joined <- joined[!is.na(joined$num_of_services),]
nrow(joined) # 2512 Observations before splitting
### Translate into current ML work ###
data.size <- nrow(joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce unexpected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- joined[training_id_integers,]
test_data <- joined[-training_id_integers,]
nrow(train_data) # 2010 to train with
nrow(test_data) # 502 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 5 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y
+ num_students.y + num_of_services
+ highest_connect_type + providers_typical_category
+ free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.x, test_data$frn_complete)
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
View(results)
results$cleaned <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
View(results)
table(results$cleaned)
results$guessed_wrong <- (results$verified_category == results$raw) & (results$predicted_category != results$raw_category)
table(results$gussed_wrong)
table(results$guessed_wrong)
results$cleaned_line_item <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
results$dirty <- results$verified_category == results$raw_category)
table(results$dirty)
results$dirty <- results$verified_category == results$raw_category)
table(results$dirty)
table(results$dirty)
table ?
asdf
table
q
str?
asdf
table(results$cleaned_line_item)
results$dirty <- results$verified_category == results$raw_category
table(results$dirty)
results$cleaned_line_item <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
results$cleaned_line_item <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
table(results$cleaned)
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.x, test_data$frn_complete)
results$clean_the_line_item? <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
table(results$clean_the_line_item?)
results$clean_the_line_item? <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
results$clean_the_line_item <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
table(results$clean_the_line_item)
View(results)
results$guessed_correctly <- results$verified_category == results$predicted_category
results$clean_the_line_item <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
table(results$clean_the_line_item)
View(results)
# Importing data and setting the current working directory.
# install.packages('caret', dependencies = TRUE)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/original_line_items.csv")
# View(raw_lis)
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/verified_line_items_real.csv")
# View(verified_lis)
# Inner join both datasets
joined <- merge(raw_lis, verified_lis, by.x=c("frn_complete"), by.y=c("frn_complete"))
# View(joined)
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
unique(is.na(joined$bandwidth_in_mbps.x))
nrow(joined)
joined <- joined[!is.na(joined$bandwidth_in_mbps.x),]
nrow(joined)
unique(is.na(joined$num_students.x))
joined <- joined[!is.na(joined$num_students.x),]
nrow(joined)
unique(is.na(joined$num_of_services))
joined <- joined[!is.na(joined$num_of_services),]
nrow(joined) # 2512 Observations before splitting
### Translate into current ML work ###
data.size <- nrow(joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce unexpected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- joined[training_id_integers,]
test_data <- joined[-training_id_integers,]
nrow(train_data) # 2010 to train with
nrow(test_data) # 502 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 5 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + cost_per_line.y
+ num_students.y + num_of_services
+ highest_connect_type + providers_typical_category
+ free_and_reduced, data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.x, test_data$frn_complete)
results$guessed_correctly <- results$verified_category == results$predicted_category
results$clean_the_line_item <- (results$verified_category == results$predicted_category) & (results$predicted_category != results$raw_category)
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
machine_learn_clean_iteration_2 <- write.csv(results, "machine_learn_clean_iteration_2.csv")
