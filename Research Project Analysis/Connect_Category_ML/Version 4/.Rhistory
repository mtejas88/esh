View(joined)
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.x = TRUE)
View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.x',
'consultant_app.x', 'cost_per_line.x', 'num_students.x',
'num_of_services.x', 'highest_connect_type.x', 'providers_typical_category.x',
'free_and_reduced.x', 'copper_line.x', 'consultants_cat.x',
'upstream_conditions_met.x', 'isp_conditions_met.x', 'ia_circuit_only.x',
'wireless_service.x', 'wan_fiber_3_lines.x', 'likely_wan_fiber.x', 'exception_not_fiber.x',
'likely_other_uncategorized.x', 'entity_type.x', 'other_location_no_district.x')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
summary(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium']
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x = FALSE,]
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x is FALSE,]
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x == FALSE,]
nrow(compacted_joined) # 6519 Observations before splitting
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.x',
'consultant_app.x', 'cost_per_line.x', 'num_students.x',
'num_of_services.x', 'highest_connect_type.x', 'providers_typical_category.x',
'free_and_reduced.x', 'copper_line.x', 'consultants_cat.x',
'upstream_conditions_met.x', 'isp_conditions_met.x', 'ia_circuit_only.x',
'wireless_service.x', 'wan_fiber_3_lines.x', 'likely_wan_fiber.x', 'exception_not_fiber.x',
'likely_other_uncategorized.x', 'entity_type.x', 'other_location_no_district.x')]
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x == FALSE,]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.x',
'consultant_app.x', 'cost_per_line.x', 'num_students.x',
'num_of_services.x', 'highest_connect_type.x', 'providers_typical_category.x',
'free_and_reduced.x', 'copper_line.x', 'consultants_cat.x',
'upstream_conditions_met.x', 'isp_conditions_met.x', 'ia_circuit_only.x',
'wireless_service.x', 'wan_fiber_3_lines.x', 'likely_wan_fiber.x', 'exception_not_fiber.x',
'likely_other_uncategorized.x', 'entity_type.x', 'other_location_no_district.x')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium',]
summary(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x != TRUE,]
nrow(compacted_joined) # 6519 Observations before splitting
compacted_joined <- na.omit(compacted_joined)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.x',
'consultant_app.x', 'cost_per_line.x', 'num_students.x',
'num_of_services.x', 'highest_connect_type.x', 'providers_typical_category.x',
'free_and_reduced.x', 'copper_line.x', 'consultants_cat.x',
'upstream_conditions_met.x', 'isp_conditions_met.x', 'ia_circuit_only.x',
'wireless_service.x', 'wan_fiber_3_lines.x', 'likely_wan_fiber.x', 'exception_not_fiber.x',
'likely_other_uncategorized.x', 'entity_type.x', 'other_location_no_district.x')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x != TRUE,]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
### Translate into current ML work ###
data.size <- nrow(compacted_joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce unexpected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- compacted_joined[training_id_integers,]
test_data <- compacted_joined[-training_id_integers,]
nrow(train_data) # 5215 to train with
nrow(test_data) # 1304 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 18 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + consultant_app.x + consultants_cat.x
+ cost_per_line.x + num_students.x + num_of_services.x + highest_connect_type.x
+ providers_typical_category.x + free_and_reduced.x + copper_line.x + upstream_conditions_met.x
+ isp_conditions_met.x + ia_circuit_only.x + wireless_service.x + wan_fiber_3_lines.x
+ likely_wan_fiber.x + exception_not_fiber.x + likely_other_uncategorized.x,
data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.x, test_data$frn_complete)
results$guessed_correctly <- results$verified_category == results$predicted_category
# clean up factors issue
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
# Importing data and setting the current working directory.
# install.packages('caret', dependencies = TRUE)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
# install.packages("RPostgreSQL")
# require("RPostgreSQL")
# loads the PostgreSQL driver
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.y = TRUE)
View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.y',
'consultant_app.y', 'cost_per_line.y', 'num_students.y',
'num_of_services.y', 'highest_connect_type.y', 'providers_typical_category.y',
'free_and_reduced.y', 'copper_line.y', 'consultants_cat.y',
'upstream_conditions_met.y', 'isp_conditions_met.y', 'ia_circuit_only.y',
'wireless_service.y', 'wan_fiber_3_lines.y', 'likely_wan_fiber.y', 'eyception_not_fiber.y',
'likely_other_uncategorized.y', 'entity_type.y', 'other_location_no_district.y')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.y != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.y != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
### Translate into current ML work ###
data.size <- nrow(compacted_joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce uneypected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- compacted_joined[training_id_integers,]
test_data <- compacted_joined[-training_id_integers,]
nrow(train_data) # 5215 to train with
nrow(test_data) # 1304 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 18 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.y + consultant_app.y + consultants_cat.y
+ cost_per_line.y + num_students.y + num_of_services.y + highest_connect_type.y
+ providers_typical_category.y + free_and_reduced.y + copper_line.y + upstream_conditions_met.y
+ isp_conditions_met.y + ia_circuit_only.y + wireless_service.y + wan_fiber_3_lines.y
+ likely_wan_fiber.y + eyception_not_fiber.y + likely_other_uncategorized.y,
data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.y, test_data$frn_complete)
results$guessed_correctly <- results$verified_category == results$predicted_category
# clean up factors issue
View(results)
confusionMatriy(predict.forest, reference=test_data$connect_category.y)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
View(results)
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.y = TRUE)
View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.y',
'consultant_app.y', 'cost_per_line.y', 'num_students.y',
'num_of_services.y', 'highest_connect_type.y', 'providers_typical_category.y',
'free_and_reduced.y', 'copper_line.y', 'consultants_cat.y',
'upstream_conditions_met.y', 'isp_conditions_met.y', 'ia_circuit_only.y',
'wireless_service.y', 'wan_fiber_3_lines.y', 'likely_wan_fiber.y', 'eyception_not_fiber.y',
'likely_other_uncategorized.y', 'entity_type.y', 'other_location_no_district.y')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.y != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.y != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.x = TRUE)
View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.y',
'consultant_app.y', 'cost_per_line.y', 'num_students.y',
'num_of_services.y', 'highest_connect_type.y', 'providers_typical_category.y',
'free_and_reduced.y', 'copper_line.y', 'consultants_cat.y',
'upstream_conditions_met.y', 'isp_conditions_met.y', 'ia_circuit_only.y',
'wireless_service.y', 'wan_fiber_3_lines.y', 'likely_wan_fiber.y', 'eyception_not_fiber.y',
'likely_other_uncategorized.y', 'entity_type.y', 'other_location_no_district.y')]
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.y',
'consultant_app.y', 'cost_per_line.y', 'num_students.y',
'num_of_services.y', 'highest_connect_type.y', 'providers_typical_category.y',
'free_and_reduced.y', 'copper_line.y', 'consultants_cat.y',
'upstream_conditions_met.y', 'isp_conditions_met.y', 'ia_circuit_only.y',
'wireless_service.y', 'wan_fiber_3_lines.y', 'likely_wan_fiber.y', 'exception_not_fiber.y',
'likely_other_uncategorized.y', 'entity_type.y', 'other_location_no_district.y')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.y != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.y != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
data.size <- nrow(compacted_joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce uneypected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- compacted_joined[training_id_integers,]
test_data <- compacted_joined[-training_id_integers,]
nrow(train_data) # 5215 to train with
nrow(test_data) # 1304 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 18 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.y + consultant_app.y + consultants_cat.y
+ cost_per_line.y + num_students.y + num_of_services.y + highest_connect_type.y
+ providers_typical_category.y + free_and_reduced.y + copper_line.y + upstream_conditions_met.y
+ isp_conditions_met.y + ia_circuit_only.y + wireless_service.y + wan_fiber_3_lines.y
+ likely_wan_fiber.y + exception_not_fiber.y + likely_other_uncategorized.y,
data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.y, test_data$frn_complete)
results$guessed_correctly <- results$verified_category == results$predicted_category
# clean up factors issue
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
# Importing data and setting the current working directory.
# install.packages('caret', dependencies = TRUE)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
# install.packages("RPostgreSQL")
# require("RPostgreSQL")
# loads the PostgreSQL driver
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.x = TRUE)
View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.y',
'consultant_app.y', 'cost_per_line.y', 'num_students.y',
'num_of_services.y', 'highest_connect_type.y', 'providers_typical_category.y',
'free_and_reduced.y', 'copper_line.y', 'consultants_cat.y',
'upstream_conditions_met.y', 'isp_conditions_met.y', 'ia_circuit_only.y',
'wireless_service.y', 'wan_fiber_3_lines.y', 'likely_wan_fiber.y', 'exception_not_fiber.y',
'likely_other_uncategorized.y', 'entity_type.y', 'other_location_no_district.y')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.y != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.y != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
### Translate into current ML work ###
data.size <- nrow(compacted_joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce uneypected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- compacted_joined[training_id_integers,]
test_data <- compacted_joined[-training_id_integers,]
nrow(train_data) # 5215 to train with
nrow(test_data) # 1304 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 18 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.y + consultant_app.y + consultants_cat.y
+ cost_per_line.y + num_students.y + num_of_services.y + highest_connect_type.y
+ providers_typical_category.y + free_and_reduced.y + copper_line.y + upstream_conditions_met.y
+ isp_conditions_met.y + ia_circuit_only.y + wireless_service.y + wan_fiber_3_lines.y
+ likely_wan_fiber.y + exception_not_fiber.y + likely_other_uncategorized.y,
data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.y, test_data$frn_complete)
results$guessed_correctly <- results$verified_category == results$predicted_category
# clean up factors issue
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
# Importing data and setting the current working directory.
# install.packages('caret', dependencies = TRUE)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
# install.packages("RPostgreSQL")
# require("RPostgreSQL")
# loads the PostgreSQL driver
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.x = TRUE)
View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.x',
'consultant_app.x', 'cost_per_line.x', 'num_students.x',
'num_of_services.x', 'highest_connect_type.x', 'providers_typical_category.x',
'free_and_reduced.x', 'copper_line.x', 'consultants_cat.x',
'upstream_conditions_met.x', 'isp_conditions_met.x', 'ia_circuit_only.x',
'wireless_service.x', 'wan_fiber_3_lines.x', 'likely_wan_fiber.x', 'exception_not_fiber.x',
'likely_other_uncategorized.x', 'entity_type.x', 'other_location_no_district.x')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
### Translate into current ML work ###
data.size <- nrow(compacted_joined)
train.size <- round(data.size *.8, 0)
test.size <- data.size - train.size
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce unexpected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- compacted_joined[training_id_integers,]
test_data <- compacted_joined[-training_id_integers,]
nrow(train_data) # 5215 to train with
nrow(test_data) # 1304 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 18 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + consultant_app.x + consultants_cat.x
+ cost_per_line.x + num_students.x + num_of_services.x + highest_connect_type.x
+ providers_typical_category.x + free_and_reduced.x + copper_line.x + upstream_conditions_met.x
+ isp_conditions_met.x + ia_circuit_only.x + wireless_service.x + wan_fiber_3_lines.x
+ likely_wan_fiber.x + exception_not_fiber.x + likely_other_uncategorized.x,
data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.x, test_data$frn_complete)
results$guessed_correctly <- results$verified_category == results$predicted_category
# clean up factors issue
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
# Importing data and setting the current working directory.
# install.packages('caret', dependencies = TRUE)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
# install.packages("RPostgreSQL")
# require("RPostgreSQL")
# loads the PostgreSQL driver
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.x = TRUE)
# View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.x',
'consultant_app.x', 'cost_per_line.x', 'num_students.x',
'num_of_services.x', 'highest_connect_type.x', 'providers_typical_category.x',
'free_and_reduced.x', 'copper_line.x', 'consultants_cat.x',
'upstream_conditions_met.x', 'isp_conditions_met.x', 'ia_circuit_only.x',
'wireless_service.x', 'wan_fiber_3_lines.x', 'likely_wan_fiber.x', 'exception_not_fiber.x',
'likely_other_uncategorized.x', 'entity_type.x', 'other_location_no_district.x')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
# Importing data and setting the current working directory.
# install.packages('caret', dependencies = TRUE)
library(class)
library(caret)
library(dplyr)
# install.packages('sqldf')
library(sqldf)
library(randomForest)
# install.packages('rfUtilities')
library(rfUtilities)
# install.packages('randomForestSRC')
library(randomForestSRC)
# install.packages('caret')
# install.packages("RPostgreSQL")
# require("RPostgreSQL")
# loads the PostgreSQL driver
setwd("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4")
verified_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/verified_line_items_v4.csv")
raw_lis <- read.csv("~/Desktop/ESH/ficher/Research Project Analysis/Connect_Category_ML/Version 4/original_line_items_v4.csv")
nrow(verified_lis)
nrow(raw_lis)
# View(verified_lis)
# left join both datasets
joined = merge(x = raw_lis, y = verified_lis, by = 'frn_complete', all.x = TRUE)
# View(joined)
sapply(joined, class)
compacted_joined <- joined[, c('connect_category.y', 'connect_category.x', 'frn_complete', 'bandwidth_in_mbps.x',
'consultant_app.x', 'cost_per_line.x', 'num_students.x',
'num_of_services.x', 'highest_connect_type.x', 'providers_typical_category.x',
'free_and_reduced.x', 'copper_line.x', 'consultants_cat.x',
'upstream_conditions_met.x', 'isp_conditions_met.x', 'ia_circuit_only.x',
'wireless_service.x', 'wan_fiber_3_lines.x', 'likely_wan_fiber.x', 'exception_not_fiber.x',
'likely_other_uncategorized.x', 'entity_type.x', 'other_location_no_district.x')]
# Begin filtering out nulls. (filtering our NA's could introduce bias too,
# so we want to be careful here about how we handle missing values.)
compacted_joined <- na.omit(compacted_joined)
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$entity_type.x != 'Consortium',]
nrow(compacted_joined)
compacted_joined <- compacted_joined[compacted_joined$other_location_no_district.x != 'true',]
nrow(compacted_joined) # 6519 Observations before splitting
summary(compacted_joined)
training_id_integers <- sample(data.size, train.size)
# Works which is great, might introduce unexpected biases though. Could be better to random sample as an optmization. ( Maybe line items from the lowest 80%
# line_item_id's in our data size are associated with a particular states. We'd want to make it random to get a fair training set across a lot of different states)
train_data <- compacted_joined[training_id_integers,]
test_data <- compacted_joined[-training_id_integers,]
nrow(train_data) # 5215 to train with
nrow(test_data) # 1304 Observations for testing
# View(train_data)
### Creating Random Forest Model, with 18 variables ###
connect.forest <- randomForest(as.factor(connect_category.y) ~ bandwidth_in_mbps.x + consultant_app.x + consultants_cat.x
+ cost_per_line.x + num_students.x + num_of_services.x + highest_connect_type.x
+ providers_typical_category.x + free_and_reduced.x + copper_line.x + upstream_conditions_met.x
+ isp_conditions_met.x + ia_circuit_only.x + wireless_service.x + wan_fiber_3_lines.x
+ likely_wan_fiber.x + exception_not_fiber.x + likely_other_uncategorized.x,
data=train_data, importance=T, ntree=501)
connect.forest$importance
varImpPlot(connect.forest)
predict.forest <- predict(connect.forest, test_data)
### Showing results:
results <- data.frame(verified_category = test_data$connect_category.y, predicted_category = predict.forest, raw_category = test_data$connect_category.x, test_data$frn_complete)
results$guessed_correctly <- results$verified_category == results$predicted_category
# clean up factors issue
View(results)
confusionMatrix(predict.forest, reference=test_data$connect_category.y)
